{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I_FkM4CGifJ",
        "outputId": "4049efbd-1baa-4884-9c9f-f8c5ce2f85c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5127 - loss: 1.5559 - val_accuracy: 0.7344 - val_loss: 1.4131\n",
            "Epoch 2/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6739 - loss: 1.3548 - val_accuracy: 0.7344 - val_loss: 1.1128\n",
            "Epoch 3/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7040 - loss: 1.0189 - val_accuracy: 0.7344 - val_loss: 0.9128\n",
            "Epoch 4/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7250 - loss: 0.8056 - val_accuracy: 0.7344 - val_loss: 0.8777\n",
            "Epoch 5/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.7175 - val_accuracy: 0.7344 - val_loss: 0.8678\n",
            "Epoch 6/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7405 - loss: 0.6565 - val_accuracy: 0.7344 - val_loss: 0.8687\n",
            "Epoch 7/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6974 - loss: 0.6881 - val_accuracy: 0.7344 - val_loss: 0.8813\n",
            "Epoch 8/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.5465 - val_accuracy: 0.7344 - val_loss: 0.8951\n",
            "Epoch 9/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.4988 - val_accuracy: 0.7188 - val_loss: 0.9168\n",
            "Epoch 10/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.4727 - val_accuracy: 0.6875 - val_loss: 0.9463\n",
            "Epoch 11/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.4812 - val_accuracy: 0.6875 - val_loss: 0.9848\n",
            "Epoch 12/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8691 - loss: 0.3582 - val_accuracy: 0.6875 - val_loss: 1.0110\n",
            "Epoch 13/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8918 - loss: 0.3566 - val_accuracy: 0.6875 - val_loss: 1.0520\n",
            "Epoch 14/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8950 - loss: 0.3526 - val_accuracy: 0.6875 - val_loss: 1.0839\n",
            "Epoch 15/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.3008 - val_accuracy: 0.6875 - val_loss: 1.1090\n",
            "Epoch 16/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.2776 - val_accuracy: 0.6875 - val_loss: 1.1458\n",
            "Epoch 17/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9110 - loss: 0.2574 - val_accuracy: 0.6875 - val_loss: 1.1634\n",
            "Epoch 18/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9139 - loss: 0.2713 - val_accuracy: 0.6875 - val_loss: 1.1827\n",
            "Epoch 19/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9213 - loss: 0.2317 - val_accuracy: 0.6875 - val_loss: 1.2012\n",
            "Epoch 20/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9169 - loss: 0.2237 - val_accuracy: 0.6875 - val_loss: 1.2206\n",
            "Epoch 21/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9157 - loss: 0.1935 - val_accuracy: 0.6875 - val_loss: 1.2339\n",
            "Epoch 22/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.2431 - val_accuracy: 0.6875 - val_loss: 1.2489\n",
            "Epoch 23/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9034 - loss: 0.2207 - val_accuracy: 0.6875 - val_loss: 1.2619\n",
            "Epoch 24/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.1956 - val_accuracy: 0.6719 - val_loss: 1.2672\n",
            "Epoch 25/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9289 - loss: 0.1789 - val_accuracy: 0.6875 - val_loss: 1.2808\n",
            "Epoch 26/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.2247 - val_accuracy: 0.6875 - val_loss: 1.2947\n",
            "Epoch 27/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.1864 - val_accuracy: 0.6875 - val_loss: 1.3068\n",
            "Epoch 28/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.1972 - val_accuracy: 0.6875 - val_loss: 1.3160\n",
            "Epoch 29/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2268 - val_accuracy: 0.6875 - val_loss: 1.3392\n",
            "Epoch 30/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.2636 - val_accuracy: 0.6719 - val_loss: 1.3319\n",
            "Epoch 31/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.1940 - val_accuracy: 0.6875 - val_loss: 1.3480\n",
            "Epoch 32/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9049 - loss: 0.1888 - val_accuracy: 0.6719 - val_loss: 1.3428\n",
            "Epoch 33/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1223 - val_accuracy: 0.6875 - val_loss: 1.3646\n",
            "Epoch 34/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.1990 - val_accuracy: 0.6875 - val_loss: 1.3657\n",
            "Epoch 35/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.1869 - val_accuracy: 0.6719 - val_loss: 1.3618\n",
            "Epoch 36/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.1474 - val_accuracy: 0.6875 - val_loss: 1.3750\n",
            "Epoch 37/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.1907 - val_accuracy: 0.6875 - val_loss: 1.3789\n",
            "Epoch 38/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.1911 - val_accuracy: 0.6875 - val_loss: 1.3887\n",
            "Epoch 39/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.1632 - val_accuracy: 0.6875 - val_loss: 1.3976\n",
            "Epoch 40/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.1842 - val_accuracy: 0.6875 - val_loss: 1.3952\n",
            "Epoch 41/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.1447 - val_accuracy: 0.6875 - val_loss: 1.4042\n",
            "Epoch 42/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.1753 - val_accuracy: 0.6875 - val_loss: 1.4050\n",
            "Epoch 43/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.1811 - val_accuracy: 0.6719 - val_loss: 1.4061\n",
            "Epoch 44/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.1737 - val_accuracy: 0.7031 - val_loss: 1.4091\n",
            "Epoch 45/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.2085 - val_accuracy: 0.6719 - val_loss: 1.4063\n",
            "Epoch 46/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1770 - val_accuracy: 0.6719 - val_loss: 1.4019\n",
            "Epoch 47/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.1942 - val_accuracy: 0.6875 - val_loss: 1.4146\n",
            "Epoch 48/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.1584 - val_accuracy: 0.6875 - val_loss: 1.4200\n",
            "Epoch 49/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.1408 - val_accuracy: 0.6875 - val_loss: 1.4252\n",
            "Epoch 50/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9322 - loss: 0.1490 - val_accuracy: 0.6875 - val_loss: 1.4251\n",
            "Epoch 51/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1371 - val_accuracy: 0.6875 - val_loss: 1.4409\n",
            "Epoch 52/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.1833 - val_accuracy: 0.6875 - val_loss: 1.4444\n",
            "Epoch 53/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.1467 - val_accuracy: 0.6875 - val_loss: 1.4411\n",
            "Epoch 54/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9299 - loss: 0.1882 - val_accuracy: 0.6719 - val_loss: 1.4377\n",
            "Epoch 55/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.2095 - val_accuracy: 0.6875 - val_loss: 1.4444\n",
            "Epoch 56/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.1836 - val_accuracy: 0.6875 - val_loss: 1.4515\n",
            "Epoch 57/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.1489 - val_accuracy: 0.6875 - val_loss: 1.4506\n",
            "Epoch 58/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.1974 - val_accuracy: 0.6875 - val_loss: 1.4532\n",
            "Epoch 59/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.1824 - val_accuracy: 0.6875 - val_loss: 1.4631\n",
            "Epoch 60/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.1607 - val_accuracy: 0.6875 - val_loss: 1.4662\n",
            "Epoch 61/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9232 - loss: 0.1702 - val_accuracy: 0.6875 - val_loss: 1.4723\n",
            "Epoch 62/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.1680 - val_accuracy: 0.6875 - val_loss: 1.4757\n",
            "Epoch 63/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.1695 - val_accuracy: 0.6875 - val_loss: 1.4669\n",
            "Epoch 64/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.1453 - val_accuracy: 0.6875 - val_loss: 1.4791\n",
            "Epoch 65/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9309 - loss: 0.1344 - val_accuracy: 0.6875 - val_loss: 1.4804\n",
            "Epoch 66/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.1298 - val_accuracy: 0.6719 - val_loss: 1.4791\n",
            "Epoch 67/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.1968 - val_accuracy: 0.6875 - val_loss: 1.4835\n",
            "Epoch 68/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9496 - loss: 0.1318 - val_accuracy: 0.6875 - val_loss: 1.4838\n",
            "Epoch 69/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.1421 - val_accuracy: 0.6719 - val_loss: 1.4857\n",
            "Epoch 70/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2023 - val_accuracy: 0.6875 - val_loss: 1.4918\n",
            "Epoch 71/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.1762 - val_accuracy: 0.6875 - val_loss: 1.4936\n",
            "Epoch 72/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.1691 - val_accuracy: 0.6875 - val_loss: 1.5001\n",
            "Epoch 73/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.1718 - val_accuracy: 0.6875 - val_loss: 1.4941\n",
            "Epoch 74/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.1840 - val_accuracy: 0.6875 - val_loss: 1.5011\n",
            "Epoch 75/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.1970 - val_accuracy: 0.6875 - val_loss: 1.5010\n",
            "Epoch 76/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.1806 - val_accuracy: 0.6875 - val_loss: 1.5039\n",
            "Epoch 77/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.1655 - val_accuracy: 0.6562 - val_loss: 1.4871\n",
            "Epoch 78/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.1437 - val_accuracy: 0.6875 - val_loss: 1.4920\n",
            "Epoch 79/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.1686 - val_accuracy: 0.6875 - val_loss: 1.5041\n",
            "Epoch 80/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.1766 - val_accuracy: 0.6719 - val_loss: 1.4947\n",
            "Epoch 81/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.1522 - val_accuracy: 0.6875 - val_loss: 1.5058\n",
            "Epoch 82/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1281 - val_accuracy: 0.6875 - val_loss: 1.5033\n",
            "Epoch 83/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.1793 - val_accuracy: 0.6562 - val_loss: 1.5008\n",
            "Epoch 84/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.1408 - val_accuracy: 0.6875 - val_loss: 1.5083\n",
            "Epoch 85/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9045 - loss: 0.1998 - val_accuracy: 0.6875 - val_loss: 1.5091\n",
            "Epoch 86/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.1766 - val_accuracy: 0.6875 - val_loss: 1.5155\n",
            "Epoch 87/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.1620 - val_accuracy: 0.6875 - val_loss: 1.5045\n",
            "Epoch 88/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.1354 - val_accuracy: 0.6875 - val_loss: 1.5170\n",
            "Epoch 89/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.1875 - val_accuracy: 0.6875 - val_loss: 1.5126\n",
            "Epoch 90/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9475 - loss: 0.1491 - val_accuracy: 0.6875 - val_loss: 1.5136\n",
            "Epoch 91/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9047 - loss: 0.1880 - val_accuracy: 0.6875 - val_loss: 1.5113\n",
            "Epoch 92/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.1777 - val_accuracy: 0.6875 - val_loss: 1.5379\n",
            "Epoch 93/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.1551 - val_accuracy: 0.6562 - val_loss: 1.5080\n",
            "Epoch 94/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.1747 - val_accuracy: 0.6875 - val_loss: 1.5274\n",
            "Epoch 95/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.2153 - val_accuracy: 0.6875 - val_loss: 1.5303\n",
            "Epoch 96/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.1976 - val_accuracy: 0.6875 - val_loss: 1.5312\n",
            "Epoch 97/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.1726 - val_accuracy: 0.6875 - val_loss: 1.5241\n",
            "Epoch 98/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.1692 - val_accuracy: 0.6719 - val_loss: 1.5234\n",
            "Epoch 99/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.1814 - val_accuracy: 0.7031 - val_loss: 1.5440\n",
            "Epoch 100/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8921 - loss: 0.1818 - val_accuracy: 0.6875 - val_loss: 1.5182\n",
            "Epoch 101/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9372 - loss: 0.1407 - val_accuracy: 0.6875 - val_loss: 1.5205\n",
            "Epoch 102/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9328 - loss: 0.1735 - val_accuracy: 0.6875 - val_loss: 1.5225\n",
            "Epoch 103/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.1609 - val_accuracy: 0.6875 - val_loss: 1.5374\n",
            "Epoch 104/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.1935 - val_accuracy: 0.6875 - val_loss: 1.5429\n",
            "Epoch 105/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.1869 - val_accuracy: 0.6875 - val_loss: 1.5287\n",
            "Epoch 106/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.1464 - val_accuracy: 0.6875 - val_loss: 1.5435\n",
            "Epoch 107/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.2044 - val_accuracy: 0.6875 - val_loss: 1.5319\n",
            "Epoch 108/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9013 - loss: 0.1805 - val_accuracy: 0.6875 - val_loss: 1.5528\n",
            "Epoch 109/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.1819 - val_accuracy: 0.6719 - val_loss: 1.5272\n",
            "Epoch 110/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9274 - loss: 0.1571 - val_accuracy: 0.6875 - val_loss: 1.5350\n",
            "Epoch 111/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9259 - loss: 0.1856 - val_accuracy: 0.6875 - val_loss: 1.5417\n",
            "Epoch 112/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9336 - loss: 0.1707 - val_accuracy: 0.6875 - val_loss: 1.5413\n",
            "Epoch 113/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9313 - loss: 0.1548 - val_accuracy: 0.6875 - val_loss: 1.5458\n",
            "Epoch 114/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8969 - loss: 0.1653 - val_accuracy: 0.6875 - val_loss: 1.5314\n",
            "Epoch 115/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9237 - loss: 0.1531 - val_accuracy: 0.6875 - val_loss: 1.5440\n",
            "Epoch 116/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1444 - val_accuracy: 0.6562 - val_loss: 1.5258\n",
            "Epoch 117/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.1845 - val_accuracy: 0.6875 - val_loss: 1.5599\n",
            "Epoch 118/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9324 - loss: 0.1391 - val_accuracy: 0.6875 - val_loss: 1.5408\n",
            "Epoch 119/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9365 - loss: 0.1439 - val_accuracy: 0.6562 - val_loss: 1.5444\n",
            "Epoch 120/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.1669 - val_accuracy: 0.6875 - val_loss: 1.5687\n",
            "Epoch 121/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.1695 - val_accuracy: 0.6875 - val_loss: 1.5511\n",
            "Epoch 122/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.1743 - val_accuracy: 0.6875 - val_loss: 1.5506\n",
            "Epoch 123/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.1657 - val_accuracy: 0.6875 - val_loss: 1.5483\n",
            "Epoch 124/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.1766 - val_accuracy: 0.6875 - val_loss: 1.5467\n",
            "Epoch 125/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.1696 - val_accuracy: 0.6875 - val_loss: 1.5529\n",
            "Epoch 126/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.1739 - val_accuracy: 0.6875 - val_loss: 1.5663\n",
            "Epoch 127/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.1512 - val_accuracy: 0.6875 - val_loss: 1.5499\n",
            "Epoch 128/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9131 - loss: 0.1957 - val_accuracy: 0.6875 - val_loss: 1.5549\n",
            "Epoch 129/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.2038 - val_accuracy: 0.6875 - val_loss: 1.5696\n",
            "Epoch 130/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9214 - loss: 0.1849 - val_accuracy: 0.6875 - val_loss: 1.5474\n",
            "Epoch 131/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2055 - val_accuracy: 0.6875 - val_loss: 1.5690\n",
            "Epoch 132/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.2064 - val_accuracy: 0.6875 - val_loss: 1.5563\n",
            "Epoch 133/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 0.1252 - val_accuracy: 0.6875 - val_loss: 1.5606\n",
            "Epoch 134/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.1815 - val_accuracy: 0.6875 - val_loss: 1.5620\n",
            "Epoch 135/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.1787 - val_accuracy: 0.6875 - val_loss: 1.5628\n",
            "Epoch 136/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2096 - val_accuracy: 0.6875 - val_loss: 1.5677\n",
            "Epoch 137/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.1653 - val_accuracy: 0.6875 - val_loss: 1.5707\n",
            "Epoch 138/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1333 - val_accuracy: 0.6875 - val_loss: 1.5813\n",
            "Epoch 139/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.1615 - val_accuracy: 0.6875 - val_loss: 1.5636\n",
            "Epoch 140/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.1938 - val_accuracy: 0.6875 - val_loss: 1.5690\n",
            "Epoch 141/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.1595 - val_accuracy: 0.6875 - val_loss: 1.5727\n",
            "Epoch 142/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.1629 - val_accuracy: 0.6875 - val_loss: 1.5644\n",
            "Epoch 143/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.1687 - val_accuracy: 0.6875 - val_loss: 1.5851\n",
            "Epoch 144/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9330 - loss: 0.1502 - val_accuracy: 0.6875 - val_loss: 1.5662\n",
            "Epoch 145/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.1614 - val_accuracy: 0.6875 - val_loss: 1.5759\n",
            "Epoch 146/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9185 - loss: 0.1720 - val_accuracy: 0.6875 - val_loss: 1.5851\n",
            "Epoch 147/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9242 - loss: 0.1555 - val_accuracy: 0.6719 - val_loss: 1.5696\n",
            "Epoch 148/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9222 - loss: 0.1661 - val_accuracy: 0.6875 - val_loss: 1.5684\n",
            "Epoch 149/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.1409 - val_accuracy: 0.6875 - val_loss: 1.5862\n",
            "Epoch 150/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9330 - loss: 0.1548 - val_accuracy: 0.6875 - val_loss: 1.5789\n",
            "Epoch 151/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.1628 - val_accuracy: 0.6875 - val_loss: 1.5870\n",
            "Epoch 152/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.1577 - val_accuracy: 0.6875 - val_loss: 1.5749\n",
            "Epoch 153/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.1674 - val_accuracy: 0.6875 - val_loss: 1.5810\n",
            "Epoch 154/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.1471 - val_accuracy: 0.6875 - val_loss: 1.5846\n",
            "Epoch 155/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.1952 - val_accuracy: 0.6875 - val_loss: 1.5872\n",
            "Epoch 156/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9148 - loss: 0.1724 - val_accuracy: 0.6875 - val_loss: 1.5993\n",
            "Epoch 157/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.1680 - val_accuracy: 0.6719 - val_loss: 1.5882\n",
            "Epoch 158/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9248 - loss: 0.1545 - val_accuracy: 0.6875 - val_loss: 1.6094\n",
            "Epoch 159/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9241 - loss: 0.1499 - val_accuracy: 0.6875 - val_loss: 1.5946\n",
            "Epoch 160/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9058 - loss: 0.1766 - val_accuracy: 0.6875 - val_loss: 1.5841\n",
            "Epoch 161/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.1770 - val_accuracy: 0.6875 - val_loss: 1.5883\n",
            "Epoch 162/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9253 - loss: 0.1706 - val_accuracy: 0.6875 - val_loss: 1.5984\n",
            "Epoch 163/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.1535 - val_accuracy: 0.6875 - val_loss: 1.5972\n",
            "Epoch 164/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.1932 - val_accuracy: 0.6875 - val_loss: 1.5780\n",
            "Epoch 165/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.1547 - val_accuracy: 0.6875 - val_loss: 1.6015\n",
            "Epoch 166/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.1766 - val_accuracy: 0.6875 - val_loss: 1.5866\n",
            "Epoch 167/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9245 - loss: 0.1524 - val_accuracy: 0.6875 - val_loss: 1.5918\n",
            "Epoch 168/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.1613 - val_accuracy: 0.6875 - val_loss: 1.5933\n",
            "Epoch 169/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.1933 - val_accuracy: 0.6875 - val_loss: 1.5887\n",
            "Epoch 170/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9153 - loss: 0.1901 - val_accuracy: 0.6875 - val_loss: 1.6053\n",
            "Epoch 171/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.1714 - val_accuracy: 0.6875 - val_loss: 1.5950\n",
            "Epoch 172/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.2037 - val_accuracy: 0.6719 - val_loss: 1.5915\n",
            "Epoch 173/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.1841 - val_accuracy: 0.6875 - val_loss: 1.5971\n",
            "Epoch 174/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.1646 - val_accuracy: 0.6875 - val_loss: 1.5978\n",
            "Epoch 175/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1397 - val_accuracy: 0.6875 - val_loss: 1.5980\n",
            "Epoch 176/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.1528 - val_accuracy: 0.6719 - val_loss: 1.5895\n",
            "Epoch 177/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9310 - loss: 0.1483 - val_accuracy: 0.6875 - val_loss: 1.6097\n",
            "Epoch 178/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9298 - loss: 0.1668 - val_accuracy: 0.6719 - val_loss: 1.5942\n",
            "Epoch 179/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9379 - loss: 0.1398 - val_accuracy: 0.6875 - val_loss: 1.6023\n",
            "Epoch 180/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.1927 - val_accuracy: 0.6875 - val_loss: 1.6060\n",
            "Epoch 181/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1385 - val_accuracy: 0.6719 - val_loss: 1.6046\n",
            "Epoch 182/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.1562 - val_accuracy: 0.6875 - val_loss: 1.5980\n",
            "Epoch 183/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.1524 - val_accuracy: 0.6719 - val_loss: 1.6164\n",
            "Epoch 184/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.1984 - val_accuracy: 0.6875 - val_loss: 1.6067\n",
            "Epoch 185/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.1340 - val_accuracy: 0.6875 - val_loss: 1.6091\n",
            "Epoch 186/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9304 - loss: 0.1327 - val_accuracy: 0.6719 - val_loss: 1.6059\n",
            "Epoch 187/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.1770 - val_accuracy: 0.6875 - val_loss: 1.6166\n",
            "Epoch 188/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.1953 - val_accuracy: 0.6875 - val_loss: 1.6042\n",
            "Epoch 189/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.1594 - val_accuracy: 0.6875 - val_loss: 1.6214\n",
            "Epoch 190/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.1792 - val_accuracy: 0.6875 - val_loss: 1.6084\n",
            "Epoch 191/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.1569 - val_accuracy: 0.6719 - val_loss: 1.6030\n",
            "Epoch 192/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9294 - loss: 0.1808 - val_accuracy: 0.6875 - val_loss: 1.6279\n",
            "Epoch 193/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9267 - loss: 0.1454 - val_accuracy: 0.6875 - val_loss: 1.6103\n",
            "Epoch 194/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9268 - loss: 0.1646 - val_accuracy: 0.6875 - val_loss: 1.6087\n",
            "Epoch 195/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.1846 - val_accuracy: 0.6875 - val_loss: 1.6186\n",
            "Epoch 196/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1397 - val_accuracy: 0.6875 - val_loss: 1.6236\n",
            "Epoch 197/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.1561 - val_accuracy: 0.6875 - val_loss: 1.6084\n",
            "Epoch 198/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9325 - loss: 0.1639 - val_accuracy: 0.6875 - val_loss: 1.6356\n",
            "Epoch 199/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.1669 - val_accuracy: 0.6875 - val_loss: 1.6295\n",
            "Epoch 200/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8814 - loss: 0.2086 - val_accuracy: 0.6875 - val_loss: 1.6115\n",
            "Epoch 201/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9321 - loss: 0.1537 - val_accuracy: 0.6875 - val_loss: 1.6393\n",
            "Epoch 202/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.1487 - val_accuracy: 0.6875 - val_loss: 1.6167\n",
            "Epoch 203/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9320 - loss: 0.1642 - val_accuracy: 0.6875 - val_loss: 1.6233\n",
            "Epoch 204/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9253 - loss: 0.1630 - val_accuracy: 0.6875 - val_loss: 1.6262\n",
            "Epoch 205/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9079 - loss: 0.1918 - val_accuracy: 0.6875 - val_loss: 1.6191\n",
            "Epoch 206/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9296 - loss: 0.1574 - val_accuracy: 0.6875 - val_loss: 1.6280\n",
            "Epoch 207/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9442 - loss: 0.1352 - val_accuracy: 0.6875 - val_loss: 1.6379\n",
            "Epoch 208/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8989 - loss: 0.1993 - val_accuracy: 0.6875 - val_loss: 1.6216\n",
            "Epoch 209/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9148 - loss: 0.1861 - val_accuracy: 0.6875 - val_loss: 1.6355\n",
            "Epoch 210/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9145 - loss: 0.1761 - val_accuracy: 0.6875 - val_loss: 1.6362\n",
            "Epoch 211/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9281 - loss: 0.1694 - val_accuracy: 0.6875 - val_loss: 1.6356\n",
            "Epoch 212/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.1711 - val_accuracy: 0.6875 - val_loss: 1.6332\n",
            "Epoch 213/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9245 - loss: 0.1617 - val_accuracy: 0.6875 - val_loss: 1.6382\n",
            "Epoch 214/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9284 - loss: 0.1661 - val_accuracy: 0.6875 - val_loss: 1.6373\n",
            "Epoch 215/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.2000 - val_accuracy: 0.6875 - val_loss: 1.6380\n",
            "Epoch 216/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.1921 - val_accuracy: 0.6875 - val_loss: 1.6407\n",
            "Epoch 217/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9047 - loss: 0.1569 - val_accuracy: 0.6875 - val_loss: 1.6529\n",
            "Epoch 218/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.2059 - val_accuracy: 0.6875 - val_loss: 1.6406\n",
            "Epoch 219/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.1591 - val_accuracy: 0.6875 - val_loss: 1.6429\n",
            "Epoch 220/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8968 - loss: 0.1913 - val_accuracy: 0.6875 - val_loss: 1.6417\n",
            "Epoch 221/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9363 - loss: 0.1623 - val_accuracy: 0.6875 - val_loss: 1.6552\n",
            "Epoch 222/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.1607 - val_accuracy: 0.6875 - val_loss: 1.6475\n",
            "Epoch 223/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.2169 - val_accuracy: 0.6875 - val_loss: 1.6401\n",
            "Epoch 224/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9049 - loss: 0.1972 - val_accuracy: 0.6875 - val_loss: 1.6505\n",
            "Epoch 225/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.1958 - val_accuracy: 0.6875 - val_loss: 1.6470\n",
            "Epoch 226/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9058 - loss: 0.1732 - val_accuracy: 0.6875 - val_loss: 1.6496\n",
            "Epoch 227/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8788 - loss: 0.2174 - val_accuracy: 0.6875 - val_loss: 1.6540\n",
            "Epoch 228/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.1809 - val_accuracy: 0.6875 - val_loss: 1.6519\n",
            "Epoch 229/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.1455 - val_accuracy: 0.6875 - val_loss: 1.6541\n",
            "Epoch 230/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.1981 - val_accuracy: 0.6875 - val_loss: 1.6561\n",
            "Epoch 231/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.1876 - val_accuracy: 0.6875 - val_loss: 1.6634\n",
            "Epoch 232/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.1450 - val_accuracy: 0.6875 - val_loss: 1.6664\n",
            "Epoch 233/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.1778 - val_accuracy: 0.6875 - val_loss: 1.6556\n",
            "Epoch 234/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8845 - loss: 0.2026 - val_accuracy: 0.6875 - val_loss: 1.6495\n",
            "Epoch 235/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.1835 - val_accuracy: 0.6875 - val_loss: 1.6912\n",
            "Epoch 236/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9364 - loss: 0.1397 - val_accuracy: 0.6875 - val_loss: 1.6574\n",
            "Epoch 237/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 0.2264 - val_accuracy: 0.6875 - val_loss: 1.6494\n",
            "Epoch 238/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.1866 - val_accuracy: 0.6875 - val_loss: 1.6448\n",
            "Epoch 239/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.1660 - val_accuracy: 0.6875 - val_loss: 1.6532\n",
            "Epoch 240/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.1914 - val_accuracy: 0.6875 - val_loss: 1.6622\n",
            "Epoch 241/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.1910 - val_accuracy: 0.6875 - val_loss: 1.6610\n",
            "Epoch 242/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.1685 - val_accuracy: 0.6875 - val_loss: 1.6673\n",
            "Epoch 243/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.1979 - val_accuracy: 0.6875 - val_loss: 1.6676\n",
            "Epoch 244/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1157 - val_accuracy: 0.6875 - val_loss: 1.6659\n",
            "Epoch 245/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.1450 - val_accuracy: 0.6875 - val_loss: 1.6643\n",
            "Epoch 246/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9494 - loss: 0.1492 - val_accuracy: 0.7031 - val_loss: 1.6833\n",
            "Epoch 247/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.2060 - val_accuracy: 0.6719 - val_loss: 1.6608\n",
            "Epoch 248/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.1646 - val_accuracy: 0.6875 - val_loss: 1.6682\n",
            "Epoch 249/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.1643 - val_accuracy: 0.6875 - val_loss: 1.6800\n",
            "Epoch 250/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8933 - loss: 0.2018 - val_accuracy: 0.6875 - val_loss: 1.6718\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "Place: Alahana Pirivena, Rating: 4.8, Address: Polonnaruwa Sri Lanka\n",
            "Place: Ahangama, Rating: 3.1449999999999982, Address: Ahangama Sri Lanka\n",
            "Place: Ahungalla, Rating: 2.8339999999999974, Address: Ahungalla Sri Lanka\n",
            "Place: Aanda Ella Fall, Rating: 4.2, Address: RatnapuraWewelwatte Rd Sri Lanka\n",
            "Place: Aberdeen Waterfall, Rating: 4.8, Address: Ginigathhena Sri Lanka\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "data = pd.read_csv('/content/places_v6.csv')\n",
        "\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "categories_encoded = encoder.fit_transform(data[['categoriess']])\n",
        "\n",
        "\n",
        "y = data['rating'].values\n",
        "\n",
        "\n",
        "y_binned = pd.cut(y, bins=5, labels=False)\n",
        "y_categorical = to_categorical(y_binned)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(categories_encoded, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=250, batch_size=10, validation_split=0.2)\n",
        "\n",
        "\n",
        "def predict_top_places(input_categories):\n",
        "\n",
        "    input_data = np.zeros((1, categories_encoded.shape[1]))\n",
        "    for category in input_categories:\n",
        "        if category in encoder.categories_[0]:\n",
        "            index = np.where(encoder.categories_[0] == category)[0][0]\n",
        "            input_data[0, index] = 1\n",
        "\n",
        "\n",
        "    predictions = model.predict(input_data)\n",
        "\n",
        "    top_indices = predictions[0].argsort()[-5:][::-1]\n",
        "\n",
        "\n",
        "    top_places = data.iloc[top_indices]\n",
        "\n",
        "\n",
        "    for index, row in top_places.iterrows():\n",
        "        print(f\"Place: {row['name']}, Rating: {row['rating']}, Address: {row['formatted_address']}\")\n",
        "\n",
        "\n",
        "input_categories = ['hiking', 'waterfalls']\n",
        "predict_top_places(input_categories)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU_gC3j7UJRU",
        "outputId": "cb136cf5-c6de-4335-bd83-3e1b3a9a7755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "model = load_model('/content/model.h5')\n",
        "\n",
        "\n",
        "data = pd.read_csv('/content/places_v6.csv')\n",
        "\n",
        "\n",
        "input_categories = ['hiking']\n",
        "\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "encoded_categories = encoder.fit_transform(data[['categoriess']]).toarray()\n",
        "\n",
        "\n",
        "input_data = np.zeros((1, encoded_categories.shape[1]))\n",
        "for category in input_categories:\n",
        "    if category in encoder.categories_[0]:\n",
        "        index = np.where(encoder.categories_[0] == category)[0][0]\n",
        "        input_data[0, index] = 1\n",
        "\n",
        "\n",
        "predictions = model.predict(input_data)\n",
        "\n",
        "\n",
        "top_indices = predictions[0].argsort()[-5:][::-1]\n",
        "\n",
        "\n",
        "top_places = data.iloc[top_indices]\n",
        "\n",
        "for index, row in top_places.iterrows():\n",
        "    print(f\"Place: {row['name']}, Rating: {row['rating']}, Address: {row['formatted_address']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxa_urNKUI7f",
        "outputId": "969e1326-d6ef-4690-e79e-4f5d4b790446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
            "Place: Alahana Pirivena, Rating: 4.8, Address: Polonnaruwa Sri Lanka\n",
            "Place: Ahangama, Rating: 3.1449999999999982, Address: Ahangama Sri Lanka\n",
            "Place: Ahungalla, Rating: 2.8339999999999974, Address: Ahungalla Sri Lanka\n",
            "Place: Aanda Ella Fall, Rating: 4.2, Address: RatnapuraWewelwatte Rd Sri Lanka\n",
            "Place: Aberdeen Waterfall, Rating: 4.8, Address: Ginigathhena Sri Lanka\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}