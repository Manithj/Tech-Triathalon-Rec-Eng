{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "places_df = pd.read_csv('places_v6.csv')  \n",
    "visitors_df = pd.read_csv('Visitors Preference Dataset.xlsx - user_data_version_3_10K_Users.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the ratings in places_df\n",
    "scaler = StandardScaler()\n",
    "places_df['rating'] = scaler.fit_transform(places_df[['rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "place_mapping = {place: idx for idx, place in enumerate(places_df['name'].unique())}\n",
    "reverse_place_mapping = {idx: place for place, idx in place_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example embedding dimension\n",
    "embedding_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy embeddings \n",
    "activity_embeddings = {activity: np.random.rand(embedding_dim) for activity in visitors_df['Preferred Activities'].explode().unique()}\n",
    "place_embeddings = {place: np.random.rand(embedding_dim) for place in places_df['categoriess'].explode().unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(embedding1, embedding2):\n",
    "    return cosine_similarity([embedding1], [embedding2])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TouristEnvironment:\n",
    "    def __init__(self, visitors_df, places_df, activity_embeddings, place_embeddings):\n",
    "        self.visitors_df = visitors_df\n",
    "        self.places_df = places_df\n",
    "        self.activity_embeddings = activity_embeddings\n",
    "        self.place_embeddings = place_embeddings\n",
    "        self.visitors = visitors_df['User ID'].unique()\n",
    "        self.places = places_df['name'].unique()\n",
    "        self.state = random.choice(self.visitors)\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = random.choice(self.visitors)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        place_id = action\n",
    "        visitor_preferences = self.visitors_df[self.visitors_df['User ID'] == self.state]\n",
    "        \n",
    "        # Convert place_id to place name\n",
    "        place_name = reverse_place_mapping.get(place_id, None)\n",
    "        if place_name is None:\n",
    "            raise ValueError(f\"Place ID {place_id} not found in reverse_place_mapping.\")\n",
    "\n",
    "        # Match place in places_df\n",
    "        matched_place = self.places_df[self.places_df['name'] == place_name]\n",
    "        \n",
    "        if matched_place.empty:\n",
    "            # Handle the case where the place is not found\n",
    "            print(f\"No place found for ID: {place_id}. Skipping this action.\")\n",
    "            return self.state, 0  \n",
    "\n",
    "        # Reward based on rating, matching activities, and bucket list presence\n",
    "        reward = 0\n",
    "        if matched_place['rating'].values[0] > 0:\n",
    "            reward += matched_place['rating'].values[0]\n",
    "\n",
    "        # Compare activity embeddings\n",
    "        preferred_activities = visitor_preferences['Preferred Activities'].values[0]\n",
    "        place_categories = matched_place['categoriess'].values[0]\n",
    "        for activity in preferred_activities:\n",
    "            activity_embedding = self.activity_embeddings.get(activity, np.zeros(embedding_dim))\n",
    "            for category in place_categories:\n",
    "                place_embedding = self.place_embeddings.get(category, np.zeros(embedding_dim))\n",
    "                reward += calculate_similarity(activity_embedding, place_embedding)\n",
    "\n",
    "        # Encode the bucket list and check if the recommended place is on it\n",
    "        bucket_list = visitor_preferences['Bucket list destinations Sri Lanka'].values[0].split(',')\n",
    "        bucket_list_encoded = [place_mapping.get(place, -1) for place in bucket_list]\n",
    "\n",
    "        if place_id in bucket_list_encoded:\n",
    "            reward += 3 \n",
    "\n",
    "        self.state = random.choice(self.visitors)  \n",
    "        return self.state, reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DQN model\n",
    "def build_dqn(state_size, action_size):\n",
    "    model = Sequential([\n",
    "        Dense(128, input_shape=(1,), activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(action_size, activation='linear')\n",
    "    ])\n",
    "    model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DQN agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, discount_factor=0.9, epsilon=0.1):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.model = build_dqn(state_size, action_size)\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return random.choice(range(self.action_size))\n",
    "        else:\n",
    "            q_values = self.model.predict(state, verbose=0)\n",
    "            return np.argmax(q_values[0])\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        target = reward + self.discount_factor * np.amax(self.model.predict(next_state, verbose=0))\n",
    "        target_f = self.model.predict(state, verbose=0)\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(state, target_f, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment and agent\n",
    "env = TouristEnvironment(visitors_df, places_df, activity_embeddings, place_embeddings)\n",
    "agent = DQNAgent(len(visitors_df['User ID'].unique()), len(places_df['name'].unique()))\n",
    "\n",
    "# Training the DQN agent\n",
    "episodes = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as dqn_tourist_model.h5\n"
     ]
    }
   ],
   "source": [
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "\n",
    "    for _ in range(10):\n",
    "        action = agent.choose_action(np.array([state]))\n",
    "        next_state, reward = env.step(action)\n",
    "        agent.learn(np.array([state]), action, reward, np.array([next_state]))\n",
    "        state = next_state\n",
    "\n",
    "# Save the trained model\n",
    "agent.model.save('dqn_tourist_model_final.h5')\n",
    "print(\"Model saved as dqn_tourist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation functions\n",
    "def recommend_place_dqn(agent, visitor_id):\n",
    "    state = np.array([visitor_id])\n",
    "    action = agent.choose_action(state)\n",
    "    recommended_place_id = reverse_place_mapping.get(action, \"Unknown Place\")\n",
    "    return recommended_place_id\n",
    "\n",
    "def recommend_top_n_places(agent, visitor_id, top_n=5):\n",
    "    state = np.array([visitor_id])\n",
    "    q_values = agent.model.predict(state, verbose=0)[0]\n",
    "    top_n_places = np.argsort(q_values)[::-1][:top_n]\n",
    "    top_n_place_ids = [reverse_place_mapping.get(i, \"Unknown Place\") for i in top_n_places]\n",
    "    return top_n_place_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\Hasitha\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model and test recommendations\n",
    "loaded_model = load_model('dqn_tourist_model_final.h5')\n",
    "loaded_agent = DQNAgent(len(visitors_df['User ID'].unique()), len(places_df['name'].unique()))\n",
    "loaded_agent.model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended place for Visitor 6260: Uduwathura Lake\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "sample_visitor_id = random.choice(visitors_df['User ID'].unique())\n",
    "recommended_place = recommend_place_dqn(loaded_agent, sample_visitor_id)\n",
    "print(f\"Recommended place for Visitor {sample_visitor_id}: {recommended_place}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended places for Visitor 6898: ['Uduwathura Lake', 'Dunhinda Waterfall', 'Belihuloya', 'Bathalagoda Tank', 'Galabedda Biso Pond']\n"
     ]
    }
   ],
   "source": [
    "# Recommend top 5 places for the visitor using the loaded model\n",
    "top_places = recommend_top_n_places(loaded_agent, sample_visitor_id, top_n=5)\n",
    "print(f\"Top 5 recommended places for Visitor {sample_visitor_id}: {top_places}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
